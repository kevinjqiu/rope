=============
 Rope Issues
=============


Release Schedule
================

*rope* will be released every two weeks and each quarter a final
version would be released.  That is:

=======  ===============
Week #   Release Number
=======  ===============
2        x.ym1
4        x.ym2
6        x.ym3
8        x.ym4
10       x.ym5
12       x.yrc1
13       x.y
=======  ===============

This is only a rough plan.  For example we might have more release
candidates before the ``x.y`` release.


Version 0.5
===========

From February 4, 2007 till May 6, 2007


Release Goals
-------------

Metaphor: Better static object inference

* Enhancing old refactorings
* Enhancing UI


Discussion
----------

Now that we handle many kinds of refactorings and we have achieved
many of rope's initial goals we can think of extending it.

nThere are many places to extend rope.  There are two main places
that can be enhanced.  One is occurrence finding mechanisms and the
other is object inference.  Among the features that are going to be
added implicit interfaces and changing structure refactorings are the
most promising ones.

* Occurrence finding
* DOI
* SOI
* Implicit interfaces
* Changing strucutre refactorings; like ``a = b`` -> ``a.set(b)``
* Advanced refactorings


Hot Topics
==========



To Be Discussed
===============

* `Better occurrence finding`_
* `Allowing non-existent resources`_
* `Python's implicit interfaces`_
* `Having virtual PyModules`_
* `Getting ready for Python 3.0`_
* Decorators and method refactorings
* Should `rope.base` be thread safe? which parts?
* Indexing source files for faster occurrence finding
* Faster module running
* Saving hard to compute information like class hierarchies to files
* Finding available refactorings


Better SOI
==========

To improve our static object inference mechanisms I propose to add a
new feature to rope to perform enhanced SOI.  Rope analyzes all
function calls in a module and saves the information in
`rope.base.oi.callinfo.CallInforManager` class.

I don't know how often and when to scan a module for SOI.  Maybe
before ``0.5`` release, rope only performs SOI when when the user
askes; just like DOI.  Performing it automatically requires it to be
efficient.  So later, after using it for some time, we'll decide about
that.


Returned Object SOI
-------------------

Since we're passed the objects parameters hold, we can perform a
better returned object SOI.  We can do that by giving parameter
objects passed and infer the object of local names once more.

Actually we have to perform two things.  We have to ask scope
`PyName`\s to forget their concluded data and change the parameters to
return what we want.

So to make it we have:

* Used `PyFunction._set_parameter_pyobjects()` to set the type
  of parameters
* Added `FunctionScope.invalidate_data()` to invalidate the
  pyobjects `AssignedName`\s and `EvaluatedName`\s hold.

And after implementing these we thought of treating function scopes
specially, since the names there cannot be accessed from outside.


Function Scopes
---------------

Another issue for implementing this feature is that function scope
variable types are dependant on the type of the parameters and should
change.  This issue seem to have some relations with implicit
interfaces.

These two problems(in the above section) points us to treating
function scopes specially.  Since function names are not accessible
from outside that function, we can perform all calculations in a
temporary place.

The problem gets worse when there are defined objects in a function
scope.  Maybe we can change pynames to support function scopes.


``.ropeproject`` Directory
==========================

Rope needs to store information for each project.  I propose to
introduce a ``.ropeproject`` directory inside each project for saving
files.

Here are some of the things we can do inside ``.ropeproject``:

* ``objectdb``: for storing information for object inference tools
* ``config.py``: Should be loaded when the project is opened

  * Indicating which files to ignore

Issues:

* Add ``project_rope_folder`` config
* When using rope as a library it might be unacceptable to make a dir
* This folder and its contents should not be on version control
* What to do about `NoProject`


``config.py``
-------------

* Push or poll model::

    def opening_project(project):
        pass

    def closing_project(project):
        pass

* Changing dot rope?::

    def starting_rope(core):
        pass

    def closing_rope(core):
        pass


Enhancing `CallInfoManager`
===========================

* Not saving return value in callinfo when we're approximating?
* Should every unknown be calculated everytime?
* When to forget old results?
* Returning a `Generator` for generator functions with unknown return type?
* Changing `callinfo` to match not exactly the same but similar args
* Using `sqlite3` to prevent holding information in memory? mocks?
* Saving `AbstractXxx`
* Better per name data holding in `callinfo`
* Not overwriting useful per object data in `callinfo`
* Some `self`\s are unknown!
* Updating our db when performing refactorings like move module


Invalidating Information
------------------------

When do we need to recalculate the information?  Currently rope does
not save anything unless an exact object is calculated; in that case
it will be used forever(That is till project is closed).  The
problems with this approach includes:

* The method might be changed in future.

  * Returned object
  * Parameter objects
  * The number of parameters

* We don't want to recalculate 'unknown's and 'none's every time
* The methods or data accessed by the method might change
* Removing out of date information

  * Methods that do not exist
  * Files that no longer exist
  * Types that do not exist

The need for invalidating data is felt more after saving object data
to disk.


Fixing Small Changes
--------------------

We don't want small changes in source files to invalidate all
information.  For example if a blank line is inserted at the top of a
file we don't want the information held for all the methods contained
in that module to be lost.


Using Less Space
----------------

* Currently we hold absolute path for files inside our project
* Using foreign keys instead of textual form for params and returned


Using A Real Database
---------------------

There are two main reasons for saving object information into disk.
One is that we can use these information in future sessions.  The
other is holding all type information in memory takes lots of space.

We can take two approaches:

* Manual DB:

  We can use a simple saving to files approach.  This won't solve the
  memory problem but it will save the data for future use.  Since
  files are written once when closing a project and loaded once when
  saving a project we can use a compression for our data not to take
  much space.

  But this approach an be enhanced much.  By holding object
  information in different files we can save or update files only
  when needed.  Also we can use `shelve` module.

* Using `sqlite3`:

  This will solve both problems but requires having `sqlite3`.
  Fortunately it is included in standard library since ``2.5``.

Saving object data requires having a good mechanisms for invalidating
information and testing.


An Implementation Proposal
--------------------------

We probably have to extend the information we hold for each individual
call info.::

  class CallInfo(object):

      parameters = None
      returned = None
      time = None
      exactness = None

      def __getstate__(self):
          pass

      def __setstate__(self, data):
          pass


The added fields does not seem to be a major memory problem since
call information is going to be saved to the disk.  We decided to
put data on the disk and use flat file databases or `shelve`
module.

Now the problem is how to organize data in files.  The data is
organized so::

  file/
    function/
      callinfo1
      callinfo2
      ...

  file/
    scope/
        pernameinfo1
        pernameinfo2
        ...


The simplest approach that we can take would be to use one file for
saving information for functions and scopes in that file.  This way
the keys are the function locations and the values are dictionaries
containing different call infos.

The most complex part is when to invalidate data.  Before going on we
should keep in mind that whatever we do is only an approaximation and
does not solve all problems.  That is mainly because even when no
resource changes it is possible that by running SOI multiple times
better data might be calculated and we can not know that.  But at
least we know that a good call info remains valid as long as no
resource gets changed.


Better Concluded Data
=====================

The main problem is when using star imports, after a module has been
invalidated its concluded data still exist.  This does not seem to be
a major memory leak, since these `_ConcludedData`\s are invalidated
and contain `None`.

* Using weak references for holding concluded data
* Changing `ImportedName` not to store the imported object in a
  concluded data.  This might slow things a bit.
* Changing `StarImport` to use a mock concluded data for its
  `ImportedModule` and `ImportedName`\s

The other suggestion here is that currently `ImportedName`\s store
object information in the concluded data of the importing module while
they can get concluded data from imported module.  The problem happens
when the imported module gets deleted.

Note that concluded attributes are:

* PyClass: superclass attributes
* PyModule: star imports
* PyPackage: ``__init__.py`` attributes


Marking Errors And Warnings In GUI
==================================

* Marking the occurrence in the buffer
* When to analyze the code?

  * When the user asks
  * When saving

* Saving error/warning information
* ``C-,``, ``C-.``
* ``C-c a p``, ``C-c a n``


Better Occurrence Finding
=========================

The current implementation for finding occurrences of a `PyName` is to
test every textual occurrence of that name has the same `PyName` or
not.  This approach does not work when a name is repeated many times
in the source.  For example renaming `self`\s are very time consuming.

Maybe we can use one of these solutions:

* Checking pyname equality only once for each scope

  This way we check each name only once for each scope.  But this is
  not applicable for attributes.  What's more `PyName`\s seem to
  cache their types already.

* Limiting the places to search for a name

  For example for renaming a parameter we search the body of that
  function and the keyword arguments passed to functions.  As another
  example function parameters never appear as attributes and class
  variables and methods never are referenced directly except in class
  body.  The search locations include:

  * module bodies
  * class bodies
  * function bodies

  Access methods include:

  * function call keyword
  * normal name access
  * attribute access

* Excluding unimported modules

  This does not seem to be a good solution.  One reason is that the
  imports might be indirect.  So we have to put a long time for
  creating import trees.

Or maybe we can use a strategy object for searching.


Getting ready for Python 3.0
============================

* Changing print to function in tests
* Not supporting old relative imports
* `iter.__next__()` instead of `iter.next()`?
* Supporting `bytes`, `input`
* Removing nonexistent dict methods and methods that will return sets
* Chaning imports after library reorganization
* Show function annotations in pydocs
* ``nonlocal``
* ``except xxx as yyy``
* ``...``
* Supporting keyword only arguments
* Set literals and comprehension ``{1, 2, 3}`` and ``{x for x in range(10)}``
* Renamed function attributes; ``f.func_whatever`` to ``f.__whatever__``
* Use new function signature
* Not using ``__cmp__``


Having Virtual `PyModule`\s
===========================

For doing this we actually need to support `VirtualProject`\s.
Because a refactoring changes the files in a project.  The
`VirtualProject` should compute the changed project tree and
act as a normal `Project`.


What Do We Gain?
----------------

After this refactoring we'll be able to mix any of the refactorings
and move toward bigger refactorings.

* Handling import changes for all modules

  One of the problems we are facing when performing refactorings is
  that imports need to be changed in some of the modules involved in
  that refactoring, but since those modules are already changed for
  that refactoring, it cannot be changed once more easily.

* Performing multiple refactorings in sequence

  For example for performing move method refactoring we can rename the
  self parameter of the method and then move the method itself.  Then
  move the imports used.

* Support for bigger refactorings

  Examples:


Consequences
------------

* Complexity of implementation

  After a change the internal representation of project should be
  updated.  This requires for example changes to `Folder.get_children`
  and `File.read`.

* Inefficiency because of multiple changes while refactoring

  If in a refactoring we perform 3 changes we might also need to
  recompute the information calculated in some of the `PyModule`\s 3
  times.  This seems inefficient.

* Inefficiency due to missing computed information computed locally

  One of the difficulties of having a set of main and many local
  `PyModule`\s is that when we compute some information in local ones
  these information might be no longer valid in global pymodules.


* Not convincing uses

  Right know the only need for performing multiple refactorings is for
  changing imports after performing a refactoring and it has been
  handled using some kind of virtual `PyModule` already.  We could not
  think of any good refactoring that needs to perform multiple basic
  refactorings.

* Lots of changes

  This refactoring needs lots of changes to `PyCore` and modules that
  use it.

* Complex design

  Managing multiple `PyCore`\s and changing `PyObject`\s to work with
  many of them at the same time seems to be hard.


Preventing Unnecessary Recomputations
-------------------------------------

* Using copy on write
* Updating global `PyCore` after performing changes


Using ASTs For Transformations
==============================

The main problem with AST nodes is that they only hold the line in
which statements appear but we need the offset.  If we add offset
information to AST nodes, we would be able to use them for all of the
tasks that we do right now using direct operations on program source
code.

Using ASTs for transforming programs requires making a new AST tree or
altering the old one and writing AST trees.  We can use the latter in
the formatter too but it seems a lot of work.


What Rope Assumes...
====================

In order to simplify problems a bit, rope makes some assumptions about
the source code.  In futures some of this restrictions might be removed.

* All of the modules should use 4 spaces for indenting and no hard tabs.
* All files that end with ``.py`` are considered to be python files and
  all others not.
* Either all files should be under version control or none.
* All ``*.txt`` files are considered in reST formats.
* XXX


Object Inference Issues
=======================


Rejecting Smalltalk `RefactoringBrowser` Approach
-------------------------------------------------

We can't use smalltalks approach because it requires the whole
tests suite to be run before each refactoring and this does not
seem appealing because it might take a lot of time.

Apart from that if we use a wrapper for a function using python
runtime mechanisms it is possible to find out from which line
a function is called, but we cannot always find the offset in that
file from which this function is called.

Although we cannot find the exact offset an occurrence happens we
can know the suspected lines and that will help us shorten the
scope for searching for occurrences considerably.

If we solve these problems we can can use a strategy for finding
occurrences.  Also Think of other ways of collecting type information.


Saving Collected Data
---------------------

Since resources might change after DTI, we should save collected data
so that they can be used even if there are small changes in some
files.  There might be two approaches to this problem.

In the first approach we can make `PyName`\s and `PyObject`\s
reference objects so that they can be used persistantly.  This
approach seems hard due to problems that might arise for updating
`PyName`\s.

The second approach seems easier to implement.  We can save collected
type information somewhere outside `PyName`\s.  Each time we need a
`PyName`\'s object we use the stored data.  In this approach we
should find someway of storing collected data so it can be used even
if there are some small changes in a resource.  The simplest way of
saving collected data is the ``(file, lineno)`` tuple.  The other is
the hierarchical representation and in this approach we save the data
like ``file.class.method``.


Considerations For A New Textual Form
-------------------------------------

Although textual forms are currently used only for transferring
running data, it can be used for saving `PyObject`\s, too.  This
might be useful if we want to save some of the collected information
to a file.

A textual form should:

* be stored
* have maximum immunity to changes
* represent all kinds of objects

The current textual form:

* ('module', file)
* ('function', file, lineno)
* ('class', file, name)
* ('instance', file, name)
* ('builtin', type, args)
* ('none')
* ('unknown')

Lot's of optimizations is possible.  But they make things more
complicated.  For example By adding a file indexing form:

* ('file', file, index)

We can replace all files in above forms to use the integer indices
specified with file command.  The main problem with this approach is
that file indices might change across different runs.  If transfering
efficiency is really a problem we can add a filter for sending and
receiving that converts the two forms.

We can also remove 'none' and 'unknown' with and empty string.


Returned Types Or Objects
-------------------------

Should we care only about the type of the returned object or we should
consider the object itself, too?

Well, it depends on the type of the objects that is returned.  If it
is an instance of a class then only the type matters.  If it is a
function, module or class then the object is important.

Indeed we should make some difference between the objects that we
only care about their types and the objects that their individual
instance is important to us.  Right now the latter group contains
only functions, classes, modules, lists, dicts and sets but this
list will be probably extended.


Python's Implicit Interfaces
============================

In python you don't have to define interfaces to declare that classes
use a specific protocol or interface.  There are lots of such examples
in standard library.

For example::

  class A(object):

      def a_method(self):
          pass

  class B(object):

      def a_method(self):
          pass

  def a_func(arg):
      arg.a_method()

  a_func(A())
  a_func(B())

Here although there is no inheritance relations between `A` and `B`,
renaming `A.a_method` should force `B.a_method` to be renamed too.

Or as another example::

  a_var = A()
  a_var.a_method()

renaming `a_var.a_method` should rename both `A.a_method` and
`B.a_method`.  That is `a_func` function defines the interface and its
members.

Now the problem is, if rope wants to support implicit interfaces, how
should it find out these interfaces and their members.


Not Supporting Implicit Interfaces
----------------------------------

If we plan not to support implicit interfaces things simplify
considerably.  Function arguments objects are the common base class
of encountered arguments and function returned value object is the
common base class of returned values.


Supporting Implicit Interfaces
------------------------------

We need to find out the way these implicit interfaces are defined.
Actually each function defines an interface for each of its parameters
and the members of this interface are the objects that are passed as
that arguement.  Another thing to keep in mind is that implicit
interfaces are extended by inheritance relation, too.  For example::

  class C(A):

      def a_method(self):
          pass

  def a_func(arg):
      arg.a_method()

  another_func(C())

Renaming `arg.a_method` not only should rename `C.a_method` but also it
it should rename `A.a_method`.

We should be careful about situations like::

  def a_func(arg):
      if isinstance(arg, A):
          arg.do_something()
      else:
          arg.do_some_other_thing()

The other issue is what to do for situations like this::

  def a_func(obj1, obj2):
      result = obj1.f(obj2)
      result.g()

The problem is we don't know the types of `obj1` and `obj2` exactly
and we have a list of types that these variables are assigned during
program execution.  `obj1.f` is not a specific method.


Implementation Issues
---------------------

To support implicit interfaces we need to make lots of changes.  First
of all we know that a function parameter can be anything, so using DOI
we have a set of objects for each parameter.  So the question that
comes up here is when do we need parameter objects.

* When refactoring and finding occurrences
* When code assisting in a function

Also for a rename refactoring we need to check all functions and methods
for implicit interfaces that are involved.  This does not seem practical.
Find someway of making it possible.  Maybe we can find
all of the occurrences of a method and for each check whether it is
invoked on a parameter or not.  Now that we have a bigger set of
methods we need to do the same for these methods.  When we're finished
we can perform the actual refactoring.  The challenge here is that we
should consider inheritance relations, too.

Among `PyName` classes `AssignedName`, `ParameterName` and
`ImportedName` might have more than one object.  And I believe
the main place to change is `StatementEvaluator` that might
return a list of pynames in ``${attribute_accesses}.name``
where `attribute_accessses` might result in more than one kind
of pyname.  This implies that `get_pyname_at` might return a list
of pynames.

`objectinfer` should be changed to find all of the objects that can
be inferred.


The GUI Mess; Working More on the UI Parts
==========================================


Version Control Commands
------------------------

* Commit; ``C-x v c``
* Update; ``C-x v u``
* Diff; ``C-x v d``
* Log; ``C-x v l``
* Revert; ``C-x v r``
* Remove; ``C-x v v``
* Status; ``C-x v s``
* Add; ``C-x v a``


Better Dialogs
--------------

Many dialogs look very similar.  They can be factored.  Continue using
`rope.ui.uihelpers` module and extend it.


Isolating Text Widget Features
------------------------------

Some of the features of GraphicalEditor can be used in other widgets.
Like completion, highlighting.


Defining the Responsibilities of `Core`
---------------------------------------

* Providing an interface to the plug-ins
* Providing methods for controlling rope?
